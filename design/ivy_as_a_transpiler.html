<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ivy as a Transpiler &mdash; Ivy 1.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="icon" type="image/png" href="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/ivy_logo_only.png?raw=true">
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ivy as a Framework" href="ivy_as_a_framework.html" />
    <link rel="prev" title="Building Blocks" href="building_blocks.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Ivy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../background.html">Background</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../design.html">Design</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="building_blocks.html">Building Blocks</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Ivy as a Transpiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#frontend-functional-apis">Frontend Functional APIs üöß</a></li>
<li class="toctree-l3"><a class="reference internal" href="#role-of-the-graph-compiler">Role of the Graph Compiler üöß</a></li>
<li class="toctree-l3"><a class="reference internal" href="#converting-network-models">Converting Network Models üöß</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ivy_as_a_framework.html">Ivy as a Framework</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_dive.html">Deep Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Functions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/compilation.html">Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/constants.html">Constants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/creation.html">Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/data_type.html">Data type</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/device.html">Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/elementwise.html">Elementwise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/general.html">General</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/gradients.html">Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/meta.html">Meta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/nest.html">Nest</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/random.html">Random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/searching.html">Searching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/set.html">Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/sorting.html">Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/statistical.html">Statistical</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functional/ivy/utility.html">Utility</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../data_classes/container.html">Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_classes/array.html">Array</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Framework Classes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../stateful/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/sequential.html">Sequential</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/module.html">Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stateful/activations.html">Activations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ivy"">Ivy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mech"">Ivy mech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vision"">Ivy vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../robot"">Ivy robot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gym"">Ivy gym</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../memory"">Ivy memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../builder"">Ivy builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models"">Ivy models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ecosystem"">Ivy ecosystem</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Ivy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../design.html">Design</a> &raquo;</li>
      <li>Ivy as a Transpiler</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/design/ivy_as_a_transpiler.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ivy-as-a-transpiler">
<h1>Ivy as a Transpiler<a class="headerlink" href="#ivy-as-a-transpiler" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>On the <a class="reference internal" href="building_blocks.html#building-blocks"><span class="std std-ref">Building Blocks</span></a> page, we explored the role of the backend functional APIs, the Ivy functional API, the
backend handler and the graph compiler. These parts are labelled (a) in the image below.</p>
<p>Here, we explain the role of the backend-specific frontends in Ivy, and how these enable automatic code conversions
between different ML frameworks. This part is labelled as (b) in the image below.</p>
<p>The code conversion tools described on this page are works in progress, as indicated by the the construction signs üöß.
This is in keeping with the rest of the documentation.</p>
<a class="reference internal image-reference" href="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/dependency_graph_with_compiler.png?raw=true"><img alt="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/dependency_graph_with_compiler.png?raw=true" class="align-center" src="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/dependency_graph_with_compiler.png?raw=true" style="width: 100%;" /></a>
<section id="frontend-functional-apis">
<h2>Frontend Functional APIs üöß<a class="headerlink" href="#frontend-functional-apis" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>While the backend API, Ivy API and backend handler enable all Ivy code to be framework-agnostic, they do not,
for example, enable PyTorch code to be framework agnostic. But with frontend APIs, we can also achieve this!</p>
<p>Let‚Äôs take a look at the how the implementation of <code class="code docutils literal notranslate"><span class="pre">clip</span></code> method would seem like in the frontends:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/jax/lax/functions.py</span>
<span class="k">def</span> <span class="nf">clamp</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span><span class="n">x</span><span class="p">,</span> <span class="n">x_max</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/numpy/general.py</span>
<span class="k">def</span> <span class="nf">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/tensorflow/general.py</span>
<span class="k">def</span> <span class="nf">clip_by_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/torch/general.py</span>
<span class="k">def</span> <span class="nf">clamp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
</pre></div>
</div>
<p>combined, we have the following situation:</p>
<a class="reference internal image-reference" href="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_backends_n_frontends.png?raw=true"><img alt="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_backends_n_frontends.png?raw=true" class="align-center" src="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_backends_n_frontends.png?raw=true" style="width: 100%;" /></a>
<p>Importantly, we can select the backend and frontend <strong>independently</strong> from one another. For example, this means we can
select a JAX backend, but also select the PyTorch frontend and write Ivy code which fully adheres to the PyTorch
functional API. In the reverse direction: we can take pre-written pure PyTorch code, replace each PyTorch function
with the equivalent function using Ivy‚Äôs PyTorch frontend, and then run this PyTorch code using JAX:</p>
<a class="reference internal image-reference" href="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_conversion.png?raw=true"><img alt="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_conversion.png?raw=true" class="align-center" src="https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/clip_conversion.png?raw=true" style="width: 100%;" /></a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>For this example it‚Äôs very simple, the differences are only syntactic, but the above process works for <strong>any</strong> function.
If there are semantic differences then these will be captured (a) in the wrapped frontend code which expresses the
frontend method as a composition of Ivy functions, and (b) in the wrapped backend code which expressed the Ivy
functions as compositions of backend methods.</p>
<p>Let‚Äôs take a more complex example and convert PyTorch method <code class="code docutils literal notranslate"><span class="pre">torch.nn.functional.one_hot()</span></code> into NumPy code.
The frontend is implemented by wrapping a single Ivy method <code class="code docutils literal notranslate"><span class="pre">ivy.one_hot()</span></code> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/torch/nn/sparse_functions.py</span>
<span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<p>Let‚Äôs look at the NumPy backend code for this Ivy method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/backends/numpy/general.py</span>
 <span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span>
     <span class="n">indices</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">depth</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">depth</span><span class="p">])</span>
</pre></div>
</div>
<p>By chaining these method together, we can now call <code class="code docutils literal notranslate"><span class="pre">torch.nn.functional.one_hot()</span></code> using NumPy:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ivy</span>
<span class="kn">import</span> <span class="nn">ivy.frontends.torch</span> <span class="k">as</span> <span class="nn">torch</span>

<span class="n">ivy</span><span class="o">.</span><span class="n">set_backend</span><span class="p">(</span><span class="s1">&#39;numpy&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">])</span>
<span class="n">ret</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>Let‚Äôs take one more example and convert TensorFlow method <code class="code docutils literal notranslate"><span class="pre">tf.cumprod()</span></code> into PyTorch code. This time, the
frontend is implemented by wrapping two Ivy methods <code class="code docutils literal notranslate"><span class="pre">ivy.cumprod()</span></code>, and <code class="code docutils literal notranslate"><span class="pre">ivy.flip()</span></code> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/frontends/tensorflow/math/general.py</span>
<span class="k">def</span> <span class="nf">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span>
</pre></div>
</div>
<p>Let‚Äôs look at the PyTorch backend code for both of these Ivy methods:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/backends/torch/general.py</span>
 <span class="k">def</span> <span class="nf">cumprod</span><span class="p">(</span>
     <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
     <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
     <span class="n">exclusive</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
     <span class="o">*</span><span class="p">,</span>
     <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
     <span class="k">if</span> <span class="n">exclusive</span><span class="p">:</span>
         <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
         <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
         <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ivy/functional/backends/torch/manipulation.py</span>
 <span class="k">def</span> <span class="nf">flip</span><span class="p">(</span>
     <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
     <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
     <span class="o">*</span><span class="p">,</span>
     <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
     <span class="n">num_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
     <span class="k">if</span> <span class="ow">not</span> <span class="n">num_dims</span><span class="p">:</span>
         <span class="k">return</span> <span class="n">x</span>
     <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
         <span class="n">new_axis</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">))</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="n">new_axis</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">axis</span>
     <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
         <span class="n">new_axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_axis</span><span class="p">]</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="n">new_axis</span> <span class="o">=</span> <span class="n">new_axis</span>
     <span class="n">new_axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="o">+</span> <span class="n">num_dims</span> <span class="k">if</span> <span class="n">item</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">new_axis</span><span class="p">]</span>
     <span class="n">ret</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_axis</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">ret</span>
</pre></div>
</div>
<p>Again, by chaining these methods together, we can now call <code class="code docutils literal notranslate"><span class="pre">tf.math.cumprod()</span></code> using PyTorch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ivy</span>
<span class="kn">import</span> <span class="nn">ivy.frontends.tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">ivy</span><span class="o">.</span><span class="n">set_backend</span><span class="p">(</span><span class="s1">&#39;torch&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="n">ret</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="role-of-the-graph-compiler">
<h2>Role of the Graph Compiler üöß<a class="headerlink" href="#role-of-the-graph-compiler" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>The very simple example above worked well, but what about even more complex PyTorch code involving Modules, Optimizers,
and other higher level objects? This is where the graph compiler plays a vital role. The graph compiler can convert any
code into its constituent functions at the functional API level for any ML framework.</p>
<p>For example, let‚Äôs take the following PyTorch code and run it using JAX:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
     <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">_linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>We cannot simply <code class="code docutils literal notranslate"><span class="pre">import</span> <span class="pre">ivy.frontends.torch</span></code> in place of <code class="code docutils literal notranslate"><span class="pre">import</span> <span class="pre">torch</span></code> as we did in the previous examples.
This is because the Ivy frontend only supports the functional API for each framework, whereas the code above makes use
of higher level classes through the use of the <code class="code docutils literal notranslate"><span class="pre">torch.nn</span></code> namespace.</p>
<p>In general, the way we convert code is by first compiling the code into its constituent functions in the core API using
Ivy‚Äôs graph compiler, and then we convert this executable graph into the new framework. For the example above,
this would look like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">ivy</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">compile_graph</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to_backend</span><span class="p">(</span><span class="s1">&#39;jax&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">jax_graph</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>However, when calling <code class="code docutils literal notranslate"><span class="pre">ivy.compile_graph()</span></code> the graph only connects the inputs to the outputs. Any other tensors
or variables which are not listed in the inputs are treated as constants in the graph. In this case, this means the
learnable weights in the Module will be treated as constants. This works fine if we only care about running inference
on our graph post-training, but this won‚Äôt enable training of the Module in JAX.</p>
</section>
<section id="converting-network-models">
<h2>Converting Network Models üöß<a class="headerlink" href="#converting-network-models" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>In order to convert a model from PyTorch to JAX, we first must convert the <code class="code docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> instance to
an <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instance using the method <code class="code docutils literal notranslate"><span class="pre">ivy.to_ivy_module()</span></code> like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">to_ivy_module</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<p>In its current form, the <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instance thinly wraps the PyTorch model into the <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code>
interface, whilst preserving the pure PyTorch backend. We can compile this network into a graph using Ivy‚Äôs graph
compiler like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">compile_graph</span><span class="p">()</span>
</pre></div>
</div>
<p>In this case, the learnable weights are treated as inputs to the graph rather than constants.</p>
<p>Now, with a compiled graph under the hood of our model, we can call <code class="code docutils literal notranslate"><span class="pre">.to_backend()</span></code> directly on
the <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instance to convert it to any backend of our choosing, like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to_backend</span><span class="p">(</span><span class="s1">&#39;jax&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The network can now be trained using Ivy‚Äôs optimizer classes with a JAX backend like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">x_in</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">((</span><span class="n">out</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">execute_with_gradients</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">v</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
</pre></div>
</div>
<p>To convert this <code class="code docutils literal notranslate"><span class="pre">ivy.Module</span></code> instance to a <code class="code docutils literal notranslate"><span class="pre">haiku.Module</span></code> instance, we can call <code class="code docutils literal notranslate"><span class="pre">.to_haiku_module()</span></code> like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to_haiku_module</span><span class="p">()</span>
</pre></div>
</div>
<p>If we want to remove Ivy from the pipeline entirely, we can then train the model in haiku like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">haiku</span> <span class="k">as</span> <span class="nn">hk</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>

<span class="n">x_in</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">out</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">loss_fn_t</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span>
<span class="n">loss_fn_t</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">without_apply_rng</span><span class="p">(</span><span class="n">loss_fn_t</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">loss_fn_t</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">update_rule</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">param</span> <span class="o">-</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">update</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss_fn_t</span><span class="o">.</span><span class="n">apply</span><span class="p">)(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_multimap</span><span class="p">(</span><span class="n">update_rule</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
</pre></div>
</div>
<p>Other JAX-specific network libraries such as Flax, Trax and Objax are also supported.</p>
<p>Overall, we have taken a <code class="code docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> instance, which can be trained using PyTorch‚Äôs optimizer classes,
and converted this to a <code class="code docutils literal notranslate"><span class="pre">haiku.Module</span></code> instance which can be trained using Haiku‚Äôs optimizer classes. The same
is true for any combination of frameworks, and for any network architecture, regardless of its complexity!</p>
<p><strong>Round Up</strong></p>
<p>Hopefully this has explained how, with the addition of backend-specific frontends, Ivy will be able to easily convert
code between different ML frameworks üôÇ works in progress, as indicated by the the construction signs üöß. This is in
keeping with the rest of the documentation.</p>
<p>Please check out the discussions on the <a class="reference external" href="https://github.com/unifyai/ivy">repo</a> for FAQs, and reach out on
<a class="reference external" href="https://discord.gg/ZVQdvbzNQJ">discord</a> if you have any questions!</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="building_blocks.html" class="btn btn-neutral float-left" title="Building Blocks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ivy_as_a_framework.html" class="btn btn-neutral float-right" title="Ivy as a Framework" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2022, Ivy Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>