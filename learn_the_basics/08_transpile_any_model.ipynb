{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpile any model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpile a `Keras` model into a `PyTorch` module."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è If you are running this notebook in Colab, you will have to install `Ivy` and some dependencies manually. You can do so by running the cell below ‚¨áÔ∏è\n",
    "\n",
    "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ivy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've already seen, `ivy.transpile` can convert functions and whole libraries from one framework to another. However, in machine learning and deep learning, much of the focus is on trainable modules. Fortunately, Ivy can manage the parameters of these modules and ensure that the transpiled module is fully compatible with the target framework. This allows you to take full advantage of the training utilities provided by any framework and to build complex models on top of the transpiled ones. Let's see how this works!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the neccessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ivy\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are examples which use more involved models in the [Guides](https://lets-unify.ai/demos#guides) section, but to keep things simple, let's define a basic convolutional network using Keras' Sequential API to use it as the starting point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use `ivy.transpile` to convert this `Keras` model to `PyTorch`. Since we are passing a framework-specific object to the `transpile` function, there is no need to specify the `source` keyword argument this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = tf.random.normal((1, 28, 28, 3))\n",
    "torch_model = ivy.transpile(model, source = \"tensorflow\", to=\"torch\", args=(input_array,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to (eager) transpilation, we now have a fully-fledged `torch.nn.module` üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(torch_model, torch.nn.Module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can pass `PyTorch` inputs (keeping the channels-last format of `Keras`, as the new computational graph is identical to the original one!) and get `PyTorch` tensors as the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0768, 0.0727, 0.0942, 0.1300, 0.1350, 0.0839, 0.1511, 0.1061, 0.0606,\n",
      "         0.0896]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_array = torch.rand((1, 28, 28, 3))\n",
    "output_array = torch_model(input_array)\n",
    "print(output_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, having a `torch.nn.Module` also enables you to train the model using PyTorch training code, and also to use the transpiled model to build more complex torch models, as shown in the [Transpiling a haiku model to build on top]() guide!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last tutorial related to the compiler/transpiler in [Learn the Basics](https://lets-unify.ai/demos#learn-the-basics). In the next tutorial, we'll go over an introduction to building models directly using Ivy üë®‚Äçüíª. If you are interested in continuing to learn about transpilation, you can check out the more complex tutorials in the [Guides](https://lets-unify.ai/demos#guides) section!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
