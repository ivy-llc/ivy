{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODSC Ivy Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install Ivy and some dependencies üòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/unifyai/ivy.git\n",
    "!cd ivy && git checkout f705efe7cb5d18df17ce6c1e20f04d0eb4933f48 && python3 -m pip install --user -e .\n",
    "!pip install dm-haiku\n",
    "!pip install kornia\n",
    "!pip install timm\n",
    "!pip install pyvis\n",
    "!pip install transformers\n",
    "exit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivy as a Framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this introduction, we will cover the fundamentals of using Ivy to write your own framework-indepent and future-proof code!\n",
    "\n",
    "If you are interested in exploring the theoretical aspects behind the contents of this notebook you can check out the [Design](https://lets-unify.ai/docs/ivy/overview/design.html) and the [Deep Dive](https://lets-unify.ai/docs/ivy/overview/deep_dive.html) sections of the documentation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's import Ivy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ivy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ivy Backend Handler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When used as a ML framework, Ivy is esentially an abstraction layer that supports multiple frameworks as the backend. This means that any code written in Ivy can be executed in any of the supported frameworks, with Ivy managing the framework-specific data structures, functions, optimizations, quirks and perks under the hood."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To switch the backend, we can use the `ivy.set_backend` function and pass the appropriate framework as a string. This is the easiest way to interact with the Backend Handler submodule, which manages the current backend and links Ivy‚Äôs objects and functions with the corresponding framework-specific ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"tensorflow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic data structure in Ivy is the `ivy.Array`. This is an abstraction of the `array` classes of the supported frameworks. Likewise, we also have `ivy.NativeArray`, which is an alias for the `array` class of the selected backend."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, there is another structure called the `ivy.Container`. It's a subclass of dict that is optimized for recursive operations. If you want to learn more about it, you can defer to the following [link](https://lets-unify.ai/docs/ivy/overview/design/ivy_as_a_framework/ivy_container.html)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs create an array using `ivy.array()`. Similarly, we can use `ivy.native_array()` to create a `torch.Tensor` now that the backend is set to `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"torch\")\n",
    "\n",
    "x = ivy.array([1, 2, 3])\n",
    "print(type(x))\n",
    "\n",
    "x = ivy.native_array([1, 2, 3])\n",
    "print(type(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ivy Functional API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ivy does not implement its own low-level (C++/CUDA) backend for its functions. Instead, it wraps the functional API of existing frameworks, unifying their fundamental functions under a common signature. For example, let‚Äôs take a look at `ivy.matmul()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"jax\")\n",
    "x1, x2 = ivy.array([[1.], [2.], [3.]]), ivy.array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))\n",
    "\n",
    "ivy.set_backend(\"tensorflow\")\n",
    "x1, x2 = ivy.array([[1.], [2.], [3.]]), ivy.array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))\n",
    "\n",
    "ivy.set_backend(\"torch\")\n",
    "x1, x2 = ivy.array([[1.], [2.], [3.]]), ivy.array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output arrays shown above are `ivy.Array` instances. To obtain the underlying native array, we need to use the `to_native()` method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you want the functions to return the native arrays directly, you can disable the `array_mode` of Ivy using `ivy.set_array_mode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_array_mode(False)\n",
    "\n",
    "ivy.set_backend(\"jax\")\n",
    "x1, x2 = ivy.native_array([[1.], [2.], [3.]]), ivy.native_array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output))\n",
    "\n",
    "ivy.set_backend(\"tensorflow\")\n",
    "x1, x2 = ivy.native_array([[1.], [2.], [3.]]), ivy.native_array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output))\n",
    "\n",
    "ivy.set_backend(\"torch\")\n",
    "x1, x2 = ivy.native_array([[1.], [2.], [3.]]), ivy.native_array([[1., 2., 3.]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output))\n",
    "\n",
    "ivy.set_array_mode(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping this in mind, you can build any function you want as a composition of Ivy functions. When executed, this function will ultimately call the current backend functions from its functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return ivy.divide(1, (1 + ivy.exp(-z)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, this means that by writing your code just once with Ivy, it becomes accessible for for use within any project regardless of the underlying framework being used!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ivy Stateful API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the slides, Ivy also has a stateful API which builds on its functional API and the `ivy.Container` class to provide high-level classes such as optimizers, network layers, or trainable modules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important stateful class within Ivy is ivy.Module, which can be used to create trainable layers and entire networks. A very simple example of an `ivy.Module` could be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(ivy.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.linear0 = ivy.Linear(input_dim, 128)\n",
    "        self.linear1 = ivy.Linear(128, output_dim)\n",
    "        ivy.Module.__init__(self)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = ivy.functional.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, we would simply have to set a backend and instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend('torch')  # set backend to PyTorch\n",
    "\n",
    "model = Regressor(input_dim=1, output_dim=1)\n",
    "optimizer = ivy.Adam(0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate some sample data and train the model using Ivy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_examples = 2000\n",
    "noise = ivy.random.random_normal(shape=(n_training_examples, 1), mean=0, std=0.1)\n",
    "x = ivy.linspace(-6, 3, n_training_examples).reshape((n_training_examples, 1))\n",
    "y = 0.2 * x ** 2 + 0.5 * x + 0.1 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, target):\n",
    "    return ivy.mean((pred - target)**2)\n",
    "\n",
    "for epoch in range(50):\n",
    "    # forward pass\n",
    "    pred = model(x)\n",
    "\n",
    "    # compute loss and gradients\n",
    "    loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(pred, y), model.v)\n",
    "\n",
    "    # update parameters\n",
    "    model.v = optimizer.step(model.v, grads)\n",
    "\n",
    "    # print current loss\n",
    "    print(f'Epoch: {epoch + 1:2d} --- Loss: {ivy.to_numpy(loss).item():.5f}')\n",
    "\n",
    "print('Finished training!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Tracer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just explored how to create framework agnostic functions and models with Ivy. Nonetheless, due to the wrapping Ivy performs on top of native functions, there is a slight performance overhead introduced with each function call. To address this, we can use Ivy's graph tracer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the Graph Tracer is to extract a fully functional, efficient graph composed only of functions from the corresponding functional APIs of the underlying framework (backend)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of using the Graph Tracer to remove the overhead introduced by Ivy, it can also be used with functions and modules written directly with a given framework. In this case, the GC will decompose any high-level API into a fully-functional graph of functions from said framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's write a simple `normalize` function using Ivy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = ivy.mean(x)\n",
    "    std = ivy.std(x)\n",
    "    return ivy.divide(ivy.subtract(x, mean), std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trace this function, simply call `ivy.trace_graph()`. To specify the underlying framework, you can pass the name of the framework as an argument using `to`. Otherwise, the current backend will be used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x0 = torch.tensor([1., 2., 3.])\n",
    "normalize_traced = ivy.trace_graph(normalize, to=\"torch\", args=(x0,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "normalize_traced.show(fname=\"graph.html\", notebook=True)\n",
    "HTML(filename=\"graph.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the traced function, which uses native `torch` operations directly, is faster than the original function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize_traced(x0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can set the `backend_compile` arg to `True` to apply the (native) target framework compilation function to Ivy's traced graph, making the resulting function even more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_native_comp = ivy.trace_graph(normalize, return_backend_compiled_fn=True, to=\"torch\", args=(x0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize_native_comp(x0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we compiled the function eagerly, which means that the compilation process happened immediately, as we have passed the arguments for tracing. However, if we don't pass any arguments to the `trace_graph` function, compilation will occur lazily, and the graph will be built only when we call the compiled function for the first time. To summarize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.tensor([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments are available -> tracing happens eagerly\n",
    "eager_graph = ivy.trace_graph(normalize, to=\"torch\", args=(x1,))\n",
    "\n",
    "# eager_graph is now torch code and runs efficiently\n",
    "ret = eager_graph(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments are not available -> tracing happens lazily\n",
    "lazy_graph = ivy.trace_graph(normalize, to=\"torch\")\n",
    "\n",
    "# The traced graph is initialized, tracing will happen here\n",
    "ret = lazy_graph(x1)\n",
    "\n",
    "# lazy_graph is now torch code and runs efficiently\n",
    "ret = lazy_graph(x1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivy as a Transpiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just learned how to write framework-agnostic code and trace it into an efficient graph. However, many codebases, libraries, and models have already been developed (and will continue to be!) using other frameworks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow for speed-of-thought research and development, Ivy also allows you to use any code directly into your project, regardless of the framework it was written in. No matter what ML code you want to use, Ivy's Transpiler is the tool for the job üõ†Ô∏è"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by transpiling a very simple `torch` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = torch.mean(x)\n",
    "    std = torch.std(x)\n",
    "    return torch.div(torch.sub(x, mean), std)\n",
    "\n",
    "jax_normalize = ivy.transpile(normalize, source=\"torch\", to=\"jax\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `trace_graph`, the `transpile` function can be used eagerly or lazily. In this particular example, transpilation is being performed lazily, since we haven't passed any arguments or keyword arguments to `ivy.transpile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "key = jax.random.PRNGKey(42)\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "x = jax.random.uniform(key, shape=(10,))\n",
    "\n",
    "jax_out = jax_normalize(x)\n",
    "print(jax_out, type(jax_out))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty much it! You can now use any function you need in your projects regardless of the framework you're using üöÄ\n",
    "\n",
    "However, transpiling functions one by one is far from ideal. But don't worry, with `transpile`, you can transpile entire libraries at once and easily bring them into your projects. Let's see how this works by transpiling `kornia`, a wisely-used computer vision library written in `torch`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "import requests\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the transpiled library by calling `transpile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_kornia = ivy.transpile(kornia, source=\"torch\", to=\"jax\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sample image and preprocess so that it has the format kornia expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000000034.jpg\"\n",
    "raw_img = Image.open(requests.get(url, stream=True).raw)\n",
    "img = jnp.transpose(jnp.array(raw_img), (2, 0, 1))\n",
    "img = jnp.expand_dims(img, 0) / 255\n",
    "display(raw_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can call any function from kornia in `jax`, as simple as that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = jax_kornia.enhance.sharpness(img, 10)\n",
    "type(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see if the transformation has been applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = np.uint8(np.array(out[0])*255)\n",
    "display(Image.fromarray(np.transpose(np_image, (1, 2, 0))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that every operation in the transpiled functions is performed natively in the target framework, which means that gradients can be tracked and the resulting functions are fully differentiable. Even after transpilation, you can still take advantage of the powerful features of your chosen framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While transpiling functions and libraries is useful, trainable modules play a critical role in ML and DL. The good news is that Ivy makes it just as easy to transpile modules and models from one framework to another with just one line of code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this demonstration, let's define a very basic CNN block using the Sequential API of `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we just defined is an instance of `tf.keras.Model`. Using `ivy.transpile`, we can effortlessly convert it into a `torch.nn.Module`, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = tf.random.normal((1, 28, 28, 3))\n",
    "torch_model = ivy.transpile(model, to=\"torch\", args=(input_array,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transpilation, we can pass a `torch` tensor and obtain the expected output. As mentioned previously, all operations are now PyTorch native functions, making them differentiable. Additionally, Ivy automatically converts all parameters of the original model to the new one, allowing you to transpile pre-trained models and fine-tune them in your preferred framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(torch_model, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = torch.rand((1, 28, 28, 3)).to(ivy.default_device(as_native=\"True\"))\n",
    "torch_model.to(ivy.default_device(as_native=\"True\"))\n",
    "output_array = torch_model(input_array)\n",
    "print(output_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have only transpiled a simple model for demonstration purposes, we can certainly transpile more complex models as well. Let's take a more complex model from `timm` and see how we can build upon transpiled modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only be using the encoder, so we can remove the unnecessary layers by setting `num_classes=0`, and then pass `pretrained=True` to download the pre-trained parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = timm.create_model(\"mixer_b16_224\", pretrained=True, num_classes=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transpile the model to tensorflow with `ivy.transpile` üîÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(1, 3, 224, 224)\n",
    "tf_mlp_encoder = ivy.transpile(mlp_encoder, to=\"tensorflow\", args=(noise,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's build a model on top of our pretrained encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = tf_mlp_encoder\n",
    "        self.output_dense = tf.keras.layers.Dense(units=1000, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.output_dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "x = tf.random.normal(shape=(1, 3, 224, 224))\n",
    "ret = model(x)\n",
    "print(type(ret), ret.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the encoder now consists of `tensorflow` functions, we can extend the transpiled modules as much as we want, leveraging existing weights and the tools and infrastructure of all frameworks üöÄ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, let's see how easily we can improve the performance of a model by transpiling a ResNet from Hugging Face from PyTorch to JAX ‚¨áÔ∏è"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the model and its corresponding feature extractor from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "arch_name = \"ResNet\"\n",
    "checkpoint_name = \"microsoft/resnet-50\"\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(checkpoint_name)\n",
    "model = AutoModel.from_pretrained(checkpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download a sample image from the COCO dataset and use the feature extractor we've just created to generate the torch tensors we'll be using during tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(\n",
    "    images=image, return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convert the model from `torch` to `haiku` simply calling `ivy.transpile()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpiled_graph = ivy.transpile(model, to=\"haiku\", kwargs=inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transpiling the model, let's see what the improvement in runtime efficiency looks like. For this we'll compile the original PyTorch model using `torch.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "def _f(**kwargs):\n",
    "  return model(**kwargs)\n",
    "\n",
    "comp_model = torch.compile(_f)\n",
    "_ = comp_model(**inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And the equivalent compilation of our `haiku` model with `jax.jit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "\n",
    "inputs_jax = feature_extractor(images=image, return_tensors=\"jax\")\n",
    "\n",
    "def _forward(**kwargs):\n",
    "  module = transpiled_graph()\n",
    "  return module(**kwargs).last_hidden_state\n",
    "\n",
    "_forward = jax.jit(_forward)\n",
    "rng_key = jax.random.PRNGKey(42)\n",
    "jax_forward = hk.transform(_forward)\n",
    "params = jax_forward.init(rng=rng_key, **inputs_jax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that both models are compiled in their corresponding frameworks, let's see how their runtime speeds compare to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = comp_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = jax_forward.apply(params, None, **inputs_jax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have made the model significantly faster with just one line of code, getting a ~2x increase in its execution speed üöÄ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as a sanity check, let's load a different image and make sure that the results are the same in both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000283921.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "inputs_jax = feature_extractor(images=image, return_tensors=\"jax\")\n",
    "out_torch = comp_model(**inputs)\n",
    "out_jax = jax_forward.apply(params, None, **inputs_jax)\n",
    "\n",
    "np.allclose(out_torch.last_hidden_state.detach().cpu().numpy(), out_jax, atol=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty much it! The results from both models are the same, but we have achieved a solid speed up by using Ivy's transpiler to convert the model to JAX!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
