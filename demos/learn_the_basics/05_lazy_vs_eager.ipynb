{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lazy vs Eager"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Understand the difference between eager and lazy graph tracing and transpilation."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "⚠️ If you are running this notebook in Colab, you will have to install `Ivy` and some dependencies manually. You can do so by running the cell below ⬇️\n",
                "\n",
                "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: ivy in /workspaces/ivy (0.0.4.0)\n",
                        "Requirement already satisfied: numpy in /opt/fw/mxnet (from ivy) (1.26.1)\n",
                        "Requirement already satisfied: einops in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.7.0)\n",
                        "Requirement already satisfied: psutil in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (5.9.6)\n",
                        "Requirement already satisfied: termcolor in /opt/fw/tensorflow (from ivy) (2.3.0)\n",
                        "Requirement already satisfied: colorama in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.4.6)\n",
                        "Requirement already satisfied: packaging in /opt/fw/tensorflow (from ivy) (23.2)\n",
                        "Requirement already satisfied: nvidia-ml-py in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (12.535.108)\n",
                        "Requirement already satisfied: diskcache in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (5.6.3)\n",
                        "Requirement already satisfied: google-auth in /opt/fw/tensorflow (from ivy) (2.23.3)\n",
                        "Requirement already satisfied: urllib3<2.0 in /root/.local/lib/python3.10/site-packages (from ivy) (1.26.18)\n",
                        "Requirement already satisfied: requests in /opt/fw/mxnet (from ivy) (2.31.0)\n",
                        "Requirement already satisfied: pyvis in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.3.2)\n",
                        "Requirement already satisfied: dill in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (0.3.7)\n",
                        "Requirement already satisfied: astunparse in /opt/fw/tensorflow (from ivy) (1.6.3)\n",
                        "Requirement already satisfied: ml-dtypes in /opt/fw/tensorflow (from ivy) (0.2.0)\n",
                        "Requirement already satisfied: cloudpickle in /opt/fw/tensorflow (from ivy) (3.0.0)\n",
                        "Requirement already satisfied: gast in /opt/fw/tensorflow (from ivy) (0.5.4)\n",
                        "Requirement already satisfied: tqdm in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ivy) (4.66.1)\n",
                        "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/fw/tensorflow (from astunparse->ivy) (0.41.3)\n",
                        "Requirement already satisfied: six<2.0,>=1.6.1 in /opt/fw/tensorflow (from astunparse->ivy) (1.16.0)\n",
                        "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/fw/tensorflow (from google-auth->ivy) (5.3.2)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/fw/tensorflow (from google-auth->ivy) (0.3.0)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/fw/tensorflow (from google-auth->ivy) (4.9)\n",
                        "Requirement already satisfied: ipython>=5.3.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pyvis->ivy) (8.17.1)\n",
                        "Requirement already satisfied: jinja2>=2.9.6 in /opt/fw/torch (from pyvis->ivy) (3.1.2)\n",
                        "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pyvis->ivy) (3.0.2)\n",
                        "Requirement already satisfied: networkx>=1.11 in /opt/fw/torch (from pyvis->ivy) (3.2.1)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/fw/mxnet (from requests->ivy) (3.3.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /opt/fw/mxnet (from requests->ivy) (3.4)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /opt/fw/mxnet (from requests->ivy) (2023.7.22)\n",
                        "Requirement already satisfied: decorator in /opt/fw/tensorflow (from ipython>=5.3.0->pyvis->ivy) (5.1.1)\n",
                        "Requirement already satisfied: jedi>=0.16 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.19.1)\n",
                        "Requirement already satisfied: matplotlib-inline in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.1.6)\n",
                        "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (3.0.39)\n",
                        "Requirement already satisfied: pygments>=2.4.0 in /opt/fw/jax (from ipython>=5.3.0->pyvis->ivy) (2.16.1)\n",
                        "Requirement already satisfied: stack-data in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (0.6.3)\n",
                        "Requirement already satisfied: traitlets>=5 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (5.13.0)\n",
                        "Requirement already satisfied: exceptiongroup in /opt/fw/paddle (from ipython>=5.3.0->pyvis->ivy) (1.1.3)\n",
                        "Requirement already satisfied: pexpect>4.3 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis->ivy) (4.8.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /opt/fw/tensorflow (from jinja2>=2.9.6->pyvis->ivy) (2.1.3)\n",
                        "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/fw/tensorflow (from pyasn1-modules>=0.2.1->google-auth->ivy) (0.5.0)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis->ivy) (0.8.3)\n",
                        "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis->ivy) (0.7.0)\n",
                        "Requirement already satisfied: wcwidth in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis->ivy) (0.2.9)\n",
                        "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (2.0.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (2.4.1)\n",
                        "Requirement already satisfied: pure-eval in /opt/miniconda/envs/multienv/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis->ivy) (0.2.2)\n",
                        "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "!pip install ivy"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`ivy.unify`, `ivy.trace_graph` and `ivy.transpile` can all be performed either eagerly or lazily. All previous examples have been performed **lazily**, which means that the unification, tracing, or transpilation process actually occurs during the first call of the **returned** function. \n",
                "\n",
                "This is because all three of these processes depend on function tracing, which requires function arguments to use for the tracing. Alternatively, the arguments can be provided during the `ivy.unify`, `ivy.trace_graph` or `ivy.transpile` call itself, in which case the process is performed **eagerly**. We show some simple examples for each case below."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Unify"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Consider again this simple `torch` function:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ivy\n",
                "import torch\n",
                "\n",
                "def normalize(x):\n",
                "    mean = torch.mean(x)\n",
                "    std = torch.std(x)\n",
                "    return torch.div(torch.sub(x, mean), std)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And let's also create the dummy `numpy` arrays as before:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import NumPy\n",
                "import numpy as np\n",
                "np.random.seed(0)\n",
                "\n",
                "# create random numpy array for testing\n",
                "x = np.random.uniform(size=10)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's assume that our target framework is `tensorflow`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-11-01 06:53:37.201733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "/workspaces/ivy/ivy/utils/exceptions.py:390: UserWarning: The current backend: 'tensorflow' does not support inplace updates natively. Ivy would quietly create new arrays when using inplace updates with this backend, leading to memory overhead (same applies for views). If you want to control your memory management, consider doing ivy.set_inplace_mode('strict') which should raise an error whenever an inplace update is attempted with this backend.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "import tensorflow as tf\n",
                "ivy.set_backend(\"tensorflow\")\n",
                "\n",
                "x = tf.constant(x)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the example below, the function is unified **lazily**, which means the first function call will execute slowly, as this is when the unification process actually occurs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:root:To preserve the tracer and transpiler caches across multiple machines, ensure that the relative path of your projects from the .ivy folder is consistent across all machines. You can do this by adding .ivy to your home folder and placing all projects in the same place relative to the home folder on all machines.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "ivy.array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "norm = ivy.unify(normalize, source=\"torch\")\n",
                "norm(x) # slow, lazy unification\n",
                "norm(x) # fast, unified on previous call"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, in the following example the unification occurs **eagerly**, and both function calls will be fast:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ivy.array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ivy.set_backend(\"tensorflow\")\n",
                "norm = ivy.unify(normalize, source=\"torch\", args=(x,))\n",
                "norm(x) # fast, unified at ivy.unify\n",
                "norm(x) # fast, unified at ivy.unify"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Trace"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The same is true for tracing. In the example below, the function is traced **lazily**, which means the first function call will execute slowly, as this is when the tracing process actually occurs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
                            "array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])>"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "norm_trace = ivy.trace_graph(norm)\n",
                "norm_trace(x) # slow, lazy graph tracing\n",
                "norm_trace(x) # fast, traced on previous call"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, in the following example the tracing occurs **eagerly**, and both function calls will be fast:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
                            "array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "norm_tracing = ivy.trace_graph(norm, args=(x,))\n",
                "norm_tracing(x) # fast, traced at ivy.trace_graph\n",
                "norm_tracing(x) # fast, traced at ivy.trace_graph"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Transpile"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The same is true for transpiling. In the example below, the function is transpiled **lazily**, which means the first function call will execute slowly, as this is when the transpilation process actually occurs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
                            "array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "norm_trans = ivy.transpile(normalize, source=\"torch\", to=\"tensorflow\")\n",
                "norm_trans(x) # slow, lazy transpilation\n",
                "norm_trans(x) # fast, transpiled on previous call"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, in the following example the transpilation occurs *eagerly*, and both function calls will be fast:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
                            "array([-0.34431235,  0.51129461, -0.06686894, -0.36452447, -0.98795534,\n",
                            "        0.15493582, -0.91630631,  1.41939619,  1.78909753, -1.19475674])>"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "norm_trans = ivy.transpile(normalize, source=\"torch\", to=\"tensorflow\", args=(x,))\n",
                "norm_trans(x) # fast, transpiled at ivy.transpile\n",
                "norm_trans(x) # fast, transpiled at ivy.transpile"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Round Up"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "That's it, you now know the difference between lazy vs eager execution for `ivy.unify`, `ivy.trace_graph` and `ivy.transpile`! Next, we'll be exploring how these three functions can all be called as function decorators!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
