{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Quickstart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get up to speed with Ivy with a quick, general introduction of its features and capabilities!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è If you are running this notebook in Colab, you will have to install `Ivy` and some extra packages manually. You can do so by running the cell below ‚¨áÔ∏è\n",
    "\n",
    "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Setting Up section of the docs.](https://unify.ai/docs/ivy/overview/contributing/setting_up.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ivy\n",
    "!pip install dm-haiku\n",
    "!pip install kornia\n",
    "!pip install timm\n",
    "!pip install pyvis\n",
    "exit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll go over the basic aspects of Ivy, which is both a transpiler and a ML framework that you can use to write framework-agnostic code and to integrate code from any framework into your existing code, tools, or infrastructure!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import Ivy and get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ivy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get familiar with Ivy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When used as a ML framework, Ivy allows you to write framework-agnostic code that can be executed as native code in your framework of choice. This means that when executed, Ivy code will use the appropriate functions and data structures, allowing you to seamlessly integrate your code with any other code and to leverage any framework-specific benefits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the backend, we simply have to call `ivy.set_backend()` and pass the framework we want to use as a string, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the data structures of Ivy. The main one is `ivy.Array`, which is an abstraction of the `array` class of the backends with extra functionalities. You can also access the corresponding class directly through `ivy.NativeArray`. \n",
    "\n",
    "There is also another structure called the `ivy.Container`, which is a subclass of dict that is optimized for recursive operations. If you want to learn more about it, you can defer to the following [link](https://unify.ai/docs/ivy/overview/design/ivy_as_a_framework/ivy_container.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"torch\")\n",
    "\n",
    "x = ivy.array([1, 2, 3])\n",
    "print(type(x))\n",
    "\n",
    "x = ivy.native_array([1, 2, 3])\n",
    "print(type(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar manner, Ivy's functional API wraps the functional API of the backends, and therefore uses native operations under the hood. Let's see an example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend(\"jax\")\n",
    "x1, x2 = ivy.array([[1], [2], [3]]), ivy.array([[1, 2, 3]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))\n",
    "\n",
    "ivy.set_backend(\"tensorflow\")\n",
    "x1, x2 = ivy.array([[1], [2], [3]]), ivy.array([[1, 2, 3]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))\n",
    "\n",
    "ivy.set_backend(\"torch\")\n",
    "x1, x2 = ivy.array([[1], [2], [3]]), ivy.array([[1, 2, 3]])\n",
    "output = ivy.matmul(x1, x2)\n",
    "print(type(output.to_native()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, calling `ivy.matmul` with different backends performs the corresponding operation in each one of the frameworks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functional API, we can define any framework-independent function that we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return ivy.divide(1, (1 + ivy.exp(-z)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ivy also has a stateful API which builds on its functional API and the `ivy.Container` class to provide high-level classes such as optimizers, network layers, or trainable modules."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important stateful class within Ivy is `ivy.Module`, which can be used to create trainable layers and entire networks. A very simple example of an `ivy.Module` could be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(ivy.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.linear0 = ivy.Linear(input_dim, 128)\n",
    "        self.linear1 = ivy.Linear(128, output_dim)\n",
    "        ivy.Module.__init__(self)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = ivy.functional.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, we would simply have to set a backend and instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivy.set_backend('torch')  # set backend to PyTorch\n",
    "\n",
    "model = Regressor(input_dim=1, output_dim=1)\n",
    "optimizer = ivy.Adam(0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate some sample data and train the model using Ivy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_examples = 2000\n",
    "noise = ivy.random.random_normal(shape=(n_training_examples, 1), mean=0, std=0.1)\n",
    "x = ivy.linspace(-6, 3, n_training_examples).reshape((n_training_examples, 1))\n",
    "y = 0.2 * x ** 2 + 0.5 * x + 0.1 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, target):\n",
    "    return ivy.mean((pred - target)**2)\n",
    "\n",
    "for epoch in range(50):\n",
    "    # forward pass\n",
    "    pred = model(x)\n",
    "\n",
    "    # compute loss and gradients\n",
    "    loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(pred, y), model.v)\n",
    "\n",
    "    # update parameters\n",
    "    model.v = optimizer.step(model.v, grads)\n",
    "\n",
    "    # print current loss\n",
    "    print(f'Epoch: {epoch + 1:2d} --- Loss: {ivy.to_numpy(loss).item():.5f}')\n",
    "\n",
    "print('Finished training!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just explored how to create framework agnostic functions and models with Ivy. Nonetheless, due to the wrapping Ivy performs on top of native functions, there is a slight performance overhead introduced with each function call. To address this, we can use Ivy's graph tracer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the Graph Tracer is to extract a fully functional, efficient graph composed only of functions from the corresponding functional APIs of the underlying framework (backend)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of using the Graph Tracer to remove the overhead introduced by Ivy, it can also be used with functions and modules written in any framework. In this case, the GC will decompose any high-level API into a fully-functional graph of functions from said framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's write a simple `normalize` function using Ivy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = ivy.mean(x)\n",
    "    std = ivy.std(x)\n",
    "    return ivy.divide(ivy.subtract(x, mean), std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trace this function, simply call `ivy.trace_graph()`. To specify the underlying framework, you can pass the name of the framework as an argument using `to`. Otherwise, the current backend will be used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x0 = torch.tensor([1., 2., 3.])\n",
    "normalize_traced = ivy.trace_graph(normalize, to=\"torch\", args=(x0,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "normalize_traced.show(fname=\"graph.html\", notebook=True)\n",
    "HTML(filename=\"graph.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the traced function, which uses native `torch` operations directly, is faster than the original function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize_traced(x0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can set the `backend_compile` arg to `True` to apply the (native) target framework compilation function to Ivy's traced graph, making the resulting function even more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_native_comp = ivy.trace_graph(normalize, backend_compile=True, to=\"torch\", args=(x0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "normalize_native_comp(x0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we traced the function eagerly, which means that the compilation process happened immediately, as we have passed the arguments for tracing. However, if we don't pass any arguments to the `trace_graph` function, compilation will occur lazily, and the graph will be built only when we call the compiled function for the first time. To summarize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.tensor([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments are available -> tracing happens eagerly\n",
    "eager_graph = ivy.trace_graph(normalize, to=\"torch\", args=(x1,))\n",
    "\n",
    "# eager_graph is now torch code and runs efficiently\n",
    "ret = eager_graph(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments are not available -> tracing happens lazily\n",
    "lazy_graph = ivy.trace_graph(normalize, to=\"torch\")\n",
    "\n",
    "# The traced graph is initialized, tracing will happen here\n",
    "ret = lazy_graph(x1)\n",
    "\n",
    "# lazy_graph is now torch code and runs efficiently\n",
    "ret = lazy_graph(x1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ivy as a Transpiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just learned how to write framework-agnostic code and trace it into an efficient graph. However, many codebases, libraries, and models have already been developed (and will continue to be!) using other frameworks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow for speed-of-thought research and development, Ivy also allows you to use any code directly into your project, regardless of the framework it was written in. No matter what ML code you want to use, Ivy's Transpiler is the tool for the job üõ†Ô∏è"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by transpiling a very simple `torch` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = torch.mean(x)\n",
    "    std = torch.std(x)\n",
    "    return torch.div(torch.sub(x, mean), std)\n",
    "\n",
    "jax_normalize = ivy.transpile(normalize, source=\"torch\", to=\"jax\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `trace_graph`, the `transpile` function can be used eagerly or lazily. In this particular example, transpilation is being performed lazily, since we haven't passed any arguments or keyword arguments to `ivy.transpile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "key = jax.random.PRNGKey(42)\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "x = jax.random.uniform(key, shape=(10,))\n",
    "\n",
    "jax_out = jax_normalize(x)\n",
    "print(jax_out, type(jax_out))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty much it! You can now use any function you need in your projects regardless of the framework you're using üöÄ\n",
    "\n",
    "However, transpiling functions one by one is far from ideal. But don't worry, with `transpile`, you can transpile entire libraries at once and easily bring them into your projects. Let's see how this works by transpiling `kornia`, a widely-used computer vision library written in `torch`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "import requests\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the transpiled library by calling `transpile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_kornia = ivy.transpile(kornia, source=\"torch\", to=\"jax\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a sample image and preprocess so that it has the format kornia expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000000034.jpg\"\n",
    "raw_img = Image.open(requests.get(url, stream=True).raw)\n",
    "img = jnp.transpose(jnp.array(raw_img), (2, 0, 1))\n",
    "img = jnp.expand_dims(img, 0) / 255\n",
    "display(raw_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can call any function from kornia in `jax`, as simple as that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = jax_kornia.enhance.sharpness(img, 10)\n",
    "type(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see if the transformation has been applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image = np.uint8(np.array(out[0])*255)\n",
    "display(Image.fromarray(np.transpose(np_image, (1, 2, 0))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that every operation in the transpiled functions is performed natively in the target framework, which means that gradients can be tracked and the resulting functions are fully differentiable. Even after transpilation, you can still take advantage of the powerful features of your chosen framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While transpiling functions and libraries is useful, trainable modules play a critical role in ML and DL. The good news is that Ivy makes it just as easy to transpile modules and models from one framework to another with just one line of code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this demonstration, let's define a very basic CNN block using the Sequential API of `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we just defined is an instance of `tf.keras.Model`. Using `ivy.transpile`, we can effortlessly convert it into a `torch.nn.Module`, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = tf.random.normal((1, 28, 28, 3))\n",
    "torch_model = ivy.transpile(model, to=\"torch\", args=(input_array,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transpilation, we can pass a `torch` tensor and obtain the expected output. As mentioned previously, all operations are now PyTorch native functions, making them differentiable. Additionally, Ivy automatically converts all parameters of the original model to the new one, allowing you to transpile pre-trained models and fine-tune them in your preferred framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(torch_model, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = torch.rand((1, 28, 28, 3)).to(ivy.default_device(as_native=\"True\"))\n",
    "torch_model.to(ivy.default_device(as_native=\"True\"))\n",
    "output_array = torch_model(input_array)\n",
    "print(output_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have only transpiled a simple model for demonstration purposes, we can certainly transpile more complex models as well. Let's take a model from `timm` and see how we can build upon transpiled modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only be using the encoder, so we can remove the unnecessary layers by setting `num_classes=0`, and then pass `pretrained=True` to download the pre-trained parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = timm.create_model(\"mixer_b16_224\", pretrained=True, num_classes=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transpile the model to tensorflow with `ivy.transpile` üîÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(1, 3, 224, 224)\n",
    "tf_mlp_encoder = ivy.transpile(mlp_encoder, to=\"tensorflow\", args=(noise,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's build a model on top of our pretrained encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = tf_mlp_encoder\n",
    "        self.output_dense = tf.keras.layers.Dense(units=1000, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.output_dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "x = tf.random.normal(shape=(1, 3, 224, 224))\n",
    "ret = model(x)\n",
    "print(type(ret), ret.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the encoder now consists of `tensorflow` functions, we can extend the transpiled modules as much as we want, leveraging existing weights and the tools and infrastructure of all frameworks üöÄ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Round Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it! You are now prepared to start using Ivy on your own! However, there are still plenty of useful resources to explore. If you want to delve deeper into Ivy's features and learn how to use them, you can visit the [Demos](https://unify.ai/demos/) page and go through the notebooks üìö"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
