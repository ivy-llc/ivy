{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpiling a PyTorch model to build on top"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpile a `timm` model to `tensorflow` and build a new model around it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è If you are running this notebook in Colab, you will have to install `Ivy` and some dependencies manually. You can do so by running the cell below ‚¨áÔ∏è\n",
    "\n",
    "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ivy\n",
    "%pip install timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Transpile Any Model](https://lets-unify.ai/demos/learn_the_basics/08_transpile_any_model.html) we have seen how to transpile a very simple model. In the **Guides**, we will focus on transpiling more involved models developed in different frameworks. \n",
    "\n",
    "In this first notebook, we will transpile a model from the PyTorch image models repo (timm) to TensorFlow, building a classifier on top of the resulting module."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's start with the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ivy\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of building our own PyTorch model, we will get one directly from the timm package!\n",
    "\n",
    "In this case, we are going to use a MLP-Mixer. We can download the pretrained weights with `pretrained=True`\n",
    "and set `num_classes=0` to only retrieve the feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = timm.create_model(\"mixer_b16_224\", pretrained=True, num_classes=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will transpile the MLP-Mixer feature extractor to TensorFlow using `ivy.transpile` and passing\n",
    "a sample `torch.Tensor` with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(1, 3, 224, 224)\n",
    "tf_mlp_encoder = ivy.transpile(mlp_encoder, to=\"tensorflow\", args=(noise,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the transpilation has been correct, let's check with a new input in both frameworks.\n",
    "Keep in mind that all the functions called within `tf_mlp_encoder` are now TensorFlow functions üîÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random(size=(1, 3, 224, 224)).astype(np.float32)\n",
    "output_torch = mlp_encoder(torch.tensor(x))\n",
    "output_tf = tf_mlp_encoder(tf.constant(x))\n",
    "print(np.allclose(output_torch.detach(), output_tf, rtol=1e-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build or own classifier using the transpiled module as the feature extractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = tf_mlp_encoder\n",
    "        self.output_dense = tf.keras.layers.Dense(units=1000, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.output_dense(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can use our new model! As we have mentioned in \"Learn the Basics\", the transpiled model\n",
    "is fully trainable in the target framework, so you can also fine-tune your transpiled modules or train\n",
    "them from the ground up! üìâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "x = tf.random.normal(shape=(1, 3, 224, 224))\n",
    "ret = model(x)\n",
    "print(type(ret), ret.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you are ready to transpile any PyTorch model, layer or trainable module and integrate it within TensorFlow, but let's keep exploring how we can convert trainable modules from (and to!) other frameworks ‚û°Ô∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
