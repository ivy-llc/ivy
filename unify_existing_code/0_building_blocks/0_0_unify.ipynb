{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0.0: Unify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, we unify a simple PyTorch function `normalize`. We then show how this newly unified `normalize` function can be used alongside *any* ML framework!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, let's import the dependencies and define the `torch` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ivy\n",
    "import torch\n",
    "\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's unify the function!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalize = ivy.unify(normalize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's it! The `normalize` function can now be used with **any ML framework**. It's as simple as that!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, let's give it a try!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import NumPy\n",
    "import numpy as np\n",
    "\n",
    "# create random NumPy arrays for testing\n",
    "x = np.randon.uniform(size=10)\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "# NumPy\n",
    "print(normalize(x, mean, std))\n",
    "\n",
    "# JAX\n",
    "import jax.numpy as jnp\n",
    "x_ = jnp.array(x)\n",
    "mean_ = jnp.array(mean)\n",
    "std_ = jnp.array(std)\n",
    "print(normalize(x_, mean_, std_))\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "x_ = tf.constant(x)\n",
    "mean_ = tf.constant(mean)\n",
    "std_ = tf.constant(std)\n",
    "print(normalize(x_, mean_, std_))\n",
    "\n",
    "# PyTorch\n",
    "x_ = torch.tensor(x)\n",
    "mean_ = torch.tensor(mean)\n",
    "std_ = torch.tensor(std)\n",
    "print(normalize(x_, mean_, std_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the new `normalize` function can operate with any ML framework. `ivy.unify` is able to detect that the original `normalize` function is implemented in PyTorch by using the `inspection` module. `ivy.unify` then converts the framework-specific PyTorch implementation into a framework-agnostic Ivy implementation, which is compatible with all frameworks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Round Up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's it, you can now unify ML code! However, there are several other important topics to master before you're ready to unify ML code like a pro ðŸ¥·. Next, we'll be learning how to make our unified Ivy code [run much more efficiently]()! âš¡"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
