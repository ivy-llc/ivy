

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ivy.functional.ivy.layers &mdash; Ivy 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> Ivy
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../background.html">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design.html">Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contributing.html">Contributing</a></li>
</ul>
<p class="caption"><span class="caption-text">Container</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/base.html">Base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/container.html">Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/creation.html">Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/data_types.html">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/device.html">Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/elementwise.html">Elementwise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/general.html">General</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/gradients.html">Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/image.html">Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/random.html">Random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/searching.html">Searching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/set.html">Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/sorting.html">Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/statistical.html">Statistical</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../container/utility.html">Utility</a></li>
</ul>
<p class="caption"><span class="caption-text">Functional</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/compilation.html">Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/constants.html">Constants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/creation.html">Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/data_type.html">Data type</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/device.html">Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/elementwise.html">Elementwise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/general.html">General</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/gradients.html">Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/image.html">Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/meta.html">Meta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/nest.html">Nest</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/random.html">Random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/searching.html">Searching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/set.html">Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/sorting.html">Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/statistical.html">Statistical</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../functional/ivy/utility.html">Utility</a></li>
</ul>
<p class="caption"><span class="caption-text">Stateful</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/module.html">Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/norms.html">Norms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/optimizers.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../stateful/sequential.html">Sequential</a></li>
</ul>
<p class="caption"><span class="caption-text">Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ivy"">Ivy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../mech"">Ivy mech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../vision"">Ivy vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../robot"">Ivy robot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../gym"">Ivy gym</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../memory"">Ivy memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../builder"">Ivy builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../models"">Ivy models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ecosystem"">Ivy ecosystem</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Ivy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>ivy.functional.ivy.layers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for ivy.functional.ivy.layers</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Collection of Ivy neural network layers in functional form.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># global</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># local</span>
<span class="kn">import</span> <span class="nn">ivy</span>
<span class="kn">from</span> <span class="nn">ivy.framework_handler</span> <span class="kn">import</span> <span class="n">current_framework</span> <span class="k">as</span> <span class="n">_cur_framework</span>


<span class="c1"># Extra #</span>
<span class="c1"># ------#</span>


<span class="c1"># Linear #</span>

<div class="viewcode-block" id="linear"><a class="viewcode-back" href="../../../../functional/ivy/layers/linear.html#ivy.functional.ivy.layers.linear">[docs]</a><span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a linear transformation to the incoming data: y = x * t(weight) + bias. The operation also supports batching</span>
<span class="sd">    of the weight matrices. This is useful if a batch of different network parameters are to be represented.</span>

<span class="sd">    :param x: The input x compute linear transformation on. *[outer_batch_shape,inner_batch_shape,in_features]*</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param weight: The weight matrix. *[outer_batch_shape,out_features,in_features]*</span>
<span class="sd">    :type weight: array</span>
<span class="sd">    :param bias: The bias vector, default is None. *[outer_batch_shape,out_features]*</span>
<span class="sd">    :type bias: array, optional</span>
<span class="sd">    :return: Result array of the linear transformation. *[outer_batch_shape,inner_batch_shape,out_features]*</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outer_batch_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">num_outer_batch_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">outer_batch_shape</span><span class="p">)</span>
    <span class="n">inner_batch_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">num_outer_batch_dims</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">num_inner_batch_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inner_batch_shape</span><span class="p">)</span>
    <span class="n">num_out_feats</span><span class="p">,</span> <span class="n">num_in_feats</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>

    <span class="c1"># OBS x IBS x OF</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ivy</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span>
        <span class="n">ivy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">outer_batch_shape</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">max</span><span class="p">(</span><span class="n">num_inner_batch_dims</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_out_feats</span><span class="p">,</span> <span class="n">num_in_feats</span><span class="p">]),</span>
        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">bias</span><span class="p">):</span>

        <span class="c1"># OBS x [1]*len(IBS) x OF</span>
        <span class="n">bias_broadcast</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">outer_batch_shape</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_inner_batch_dims</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_out_feats</span><span class="p">])</span>

        <span class="c1"># OBS x IBS x OF</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">bias_broadcast</span>

    <span class="c1"># OBS x IBS x OF</span>
    <span class="k">return</span> <span class="n">y</span></div>


<span class="c1"># Dropout #</span>

<div class="viewcode-block" id="dropout"><a class="viewcode-back" href="../../../../functional/ivy/layers/dropout.html#ivy.functional.ivy.layers.dropout">[docs]</a><span class="k">def</span> <span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoull</span>
<span class="sd">    distribution.</span>

<span class="sd">    :param x: The input array x to perform dropout on.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param prob: The probability of zeroing out each array element.</span>
<span class="sd">    :type prob: float</span>
<span class="sd">    :param scale: Whether to scale the output by 1/(1-prob), default is True.</span>
<span class="sd">    :type scale: bool, optional</span>
<span class="sd">    :return: Result array of the linear transformation. *[N,∗,out_features]*</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># noinspection PyUnresolvedReferences</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dev</span><span class="o">=</span><span class="n">ivy</span><span class="o">.</span><span class="n">dev</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">prob</span><span class="p">,</span> <span class="n">ivy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scale</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">*=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prob</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Attention #</span>

<div class="viewcode-block" id="scaled_dot_product_attention"><a class="viewcode-back" href="../../../../functional/ivy/layers/scaled_dot_product_attention.html#ivy.functional.ivy.layers.scaled_dot_product_attention">[docs]</a><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies scaled dot product attention to inputs x using optional mask.</span>

<span class="sd">    :param q: The queries *[batch_shape,num_queries,feat_dim]*.</span>
<span class="sd">    :type q: array</span>
<span class="sd">    :param k: The keys *[batch_shape,num_keys,feat_dim]*.</span>
<span class="sd">    :type k: array</span>
<span class="sd">    :param v: The values *[batch_shape,num_keys,feat_dim]*.</span>
<span class="sd">    :type v: array</span>
<span class="sd">    :param scale: The value by which to scale the query-key pairs before softmax.</span>
<span class="sd">    :type scale: float</span>
<span class="sd">    :param mask: The mask to apply to the query-key values. Default is None. *[batch_shape,num_queries,num_keys]*</span>
<span class="sd">    :type mask: array, optional</span>
<span class="sd">    :return The output following application of scaled dot-product attention. *[batch_shape,num_queries,feat_dim]*</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># BS x Q x K</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;... q f, ... k f -&gt; ... q k&#39;</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>

    <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>

        <span class="c1"># BS x Q x K</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">ivy</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="o">-</span><span class="n">ivy</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">sim</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">as_str</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> <span class="n">sim</span><span class="p">)</span>

    <span class="c1"># BS x Q x K</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># BS x Q x F</span>
    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;... q k, ... k f -&gt; ... q f&#39;</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></div>


<div class="viewcode-block" id="multi_head_attention"><a class="viewcode-back" href="../../../../functional/ivy/layers/multi_head_attention.html#ivy.functional.ivy.layers.multi_head_attention">[docs]</a><span class="k">def</span> <span class="nf">multi_head_attention</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_q_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_kv_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_out_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">to_q_v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_kv_v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_out_v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies multi-head attention to inputs x.</span>

<span class="sd">    :param x: The array to determine the queries from *[batch_shape,num_queries,x_feat_dim]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param scale: The value by which to scale the query-key similarity measure before softmax.</span>
<span class="sd">    :type scale: float</span>
<span class="sd">    :param num_heads: The number of attention heads to use.</span>
<span class="sd">    :type num_heads: int</span>
<span class="sd">    :param context: The array to determine the keys and values from. Default is None.</span>
<span class="sd">                    *[batch_shape,num_keys,cont_feat_dim]*.</span>
<span class="sd">    :type context: array, optional</span>
<span class="sd">    :param mask: The mask to apply to the query-key values. Default is None. *[batch_shape,num_queries,num_keys]*</span>
<span class="sd">    :type mask: array, optional</span>
<span class="sd">    :param to_q_fn: The function to compute queries from input x, returning queries</span>
<span class="sd">                    *[batch_shape,num_queries,numheads×feat_dim]*.</span>
<span class="sd">    :type to_q_fn: callable</span>
<span class="sd">    :param to_kv_fn: The function to compute keys and values from the context.</span>
<span class="sd">    :type to_kv_fn: callable</span>
<span class="sd">    :param to_out_fn: The function to compute the output from the scaled dot-product attention.</span>
<span class="sd">    :type to_out_fn: callable</span>
<span class="sd">    :param to_q_v: The variables for function to_q_fn. Default is None.</span>
<span class="sd">    :type to_q_v: variables array, optional</span>
<span class="sd">    :param to_kv_v: The variables for function to_kv_fn. Default is None.</span>
<span class="sd">    :type to_kv_v: variables array, optional</span>
<span class="sd">    :param to_out_v: The variables for function to_out_fn. Default is None.</span>
<span class="sd">    :type to_out_v: variables array, optional</span>
<span class="sd">    :return The output following application of multi-head attention. *[batch_shape,num_queries,out_feat_dim]*</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># BS x Q x (HxF)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">to_q_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">to_q_v</span><span class="p">)</span> <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">to_q_fn</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span>

    <span class="c1"># BS x K x CF</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="c1"># BS x K x (2xHxF)    or    BS x K x (HxF),  BS x K x (HxF)</span>
    <span class="n">kv</span> <span class="o">=</span> <span class="n">to_kv_fn</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">to_kv_v</span><span class="p">)</span> <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">to_kv_fn</span><span class="p">)</span> <span class="k">else</span> <span class="n">ivy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># BS x K x (HxF),  BS x K x (HxF)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kv</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">kv</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">kv</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># BS x H x Q x F,  BS x H x K x F,  BS x H x K x F</span>
    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">ivy</span><span class="o">.</span><span class="n">einops_rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="s1">&#39;... n (h f) -&gt; ... h n f&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">num_heads</span><span class="p">),</span> <span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>

    <span class="c1"># BS x H x Q x K</span>
    <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">einops_repeat</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="s1">&#39;... q k -&gt; ... h q k&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">num_heads</span><span class="p">)</span>

    <span class="c1"># BS x H x Q x F</span>
    <span class="n">sdpa</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="c1"># BS x Q x (HxF)</span>
    <span class="n">sdpa</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">einops_rearrange</span><span class="p">(</span><span class="n">sdpa</span><span class="p">,</span> <span class="s1">&#39;... h q f -&gt; ... q (h f)&#39;</span><span class="p">)</span>

    <span class="c1"># BS x Q x OF</span>
    <span class="k">return</span> <span class="n">to_out_fn</span><span class="p">(</span><span class="n">sdpa</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">to_out_v</span><span class="p">)</span> <span class="k">if</span> <span class="n">ivy</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">to_out_fn</span><span class="p">)</span> <span class="k">else</span> <span class="n">sdpa</span></div>


<span class="c1"># Convolutions #</span>

<div class="viewcode-block" id="conv1d"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv1d.html#ivy.functional.ivy.layers.conv1d">[docs]</a><span class="k">def</span> <span class="nf">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 1-D convolution given 3-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param data_format: &quot;NWC&quot; or &quot;NCW&quot;. Defaults to &quot;NWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<div class="viewcode-block" id="conv1d_transpose"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv1d_transpose.html#ivy.functional.ivy.layers.conv1d_transpose">[docs]</a><span class="k">def</span> <span class="nf">conv1d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 1-D transpose convolution given 3-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param output_shape: Shape of the output</span>
<span class="sd">    :type output_shape: sequence of ints, needed for TensorFlow</span>
<span class="sd">    :param data_format: &quot;NWC&quot; or &quot;NCW&quot;. Defaults to &quot;NWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the transpose convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv1d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<div class="viewcode-block" id="conv2d"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv2d.html#ivy.functional.ivy.layers.conv2d">[docs]</a><span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 2-D convolution given 4-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,h,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fh,fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param data_format: &quot;NHWC&quot; or &quot;NCHW&quot;. Defaults to &quot;NHWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<div class="viewcode-block" id="conv2d_transpose"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv2d_transpose.html#ivy.functional.ivy.layers.conv2d_transpose">[docs]</a><span class="k">def</span> <span class="nf">conv2d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 2-D transpose convolution given 4-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,h,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fh,fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param output_shape: Shape of the output</span>
<span class="sd">    :type output_shape: sequence of ints, needed for TensorFlow</span>
<span class="sd">    :param data_format: &quot;NHWC&quot; or &quot;NCHW&quot;. Defaults to &quot;NHWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the transpose convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<div class="viewcode-block" id="depthwise_conv2d"><a class="viewcode-back" href="../../../../functional/ivy/layers/depthwise_conv2d.html#ivy.functional.ivy.layers.depthwise_conv2d">[docs]</a><span class="k">def</span> <span class="nf">depthwise_conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 2-D depthwise convolution given 4-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,h,w,d]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fh,fw,d]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param data_format: &quot;NHWC&quot; or &quot;NCHW&quot;. Defaults to &quot;NHWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<span class="c1"># noinspection PyDefaultArgument</span>
<div class="viewcode-block" id="conv3d"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv3d.html#ivy.functional.ivy.layers.conv3d">[docs]</a><span class="k">def</span> <span class="nf">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NDHWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 3-D convolution given 5-D input x and filters arrays.</span>

<span class="sd">    :param x: Input volume *[batch_size,d,h,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fd,fh,fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param data_format: &quot;NDHWC&quot; or &quot;NCDHW&quot;. Defaults to &quot;NDHWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<div class="viewcode-block" id="conv3d_transpose"><a class="viewcode-back" href="../../../../functional/ivy/layers/conv3d_transpose.html#ivy.functional.ivy.layers.conv3d_transpose">[docs]</a><span class="k">def</span> <span class="nf">conv3d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NDHWC&#39;</span><span class="p">,</span> <span class="n">dilations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a 3-D transpose convolution given 5-D input x and filters arrays.</span>

<span class="sd">    :param x: Input image *[batch_size,d,h,w,d_in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param filters: Convolution filters *[fd,fh,fw,d_in,d_out]*.</span>
<span class="sd">    :type filters: array</span>
<span class="sd">    :param strides: The stride of the sliding window for each dimension of input.</span>
<span class="sd">    :type strides: int or sequence of ints</span>
<span class="sd">    :param padding: &quot;SAME&quot; or &quot;VALID&quot; indicating the algorithm, or list indicating the per-dimension paddings.</span>
<span class="sd">    :type padding: string or sequence of ints</span>
<span class="sd">    :param output_shape: Shape of the output</span>
<span class="sd">    :type output_shape: sequence of ints, needed for TensorFlow</span>
<span class="sd">    :param data_format: &quot;NDHWC&quot; or &quot;NCDHW&quot;. Defaults to &quot;NDHWC&quot;.</span>
<span class="sd">    :type data_format: string</span>
<span class="sd">    :param dilations: The dilation factor for each dimension of input.</span>
<span class="sd">    :type dilations: int or sequence of ints</span>
<span class="sd">    :return: The result of the transpose convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cur_framework</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">conv3d_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">dilations</span><span class="p">)</span></div>


<span class="c1"># LSTM #</span>

<div class="viewcode-block" id="lstm_update"><a class="viewcode-back" href="../../../../functional/ivy/layers/lstm_update.html#ivy.functional.ivy.layers.lstm_update">[docs]</a><span class="k">def</span> <span class="nf">lstm_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">init_h</span><span class="p">,</span> <span class="n">init_c</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">recurrent_kernel</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">recurrent_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform long-short term memory update by unrolling time dimension of input array.</span>

<span class="sd">    :param x: input tensor of LSTM layer *[batch_shape, t, in]*.</span>
<span class="sd">    :type x: array</span>
<span class="sd">    :param init_h: initial state tensor for the cell output *[batch_shape, out]*.</span>
<span class="sd">    :type init_h: array</span>
<span class="sd">    :param init_c: initial state tensor for the cell hidden state *[batch_shape, out]*.</span>
<span class="sd">    :type init_c: array</span>
<span class="sd">    :param kernel: weights for cell kernel *[in, 4 x out]*.</span>
<span class="sd">    :type kernel: array</span>
<span class="sd">    :param recurrent_kernel: weights for cell recurrent kernel *[out, 4 x out]*.</span>
<span class="sd">    :type recurrent_kernel: array</span>
<span class="sd">    :param bias: bias for cell kernel *[4 x out]*.</span>
<span class="sd">    :type bias: array</span>
<span class="sd">    :param recurrent_bias: bias for cell recurrent kernel *[4 x out]*.</span>
<span class="sd">    :type recurrent_bias: array</span>
<span class="sd">    :return: hidden state for all timesteps *[batch_shape,t,out]* and cell state for last timestep *[batch_shape,out]*</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># get shapes</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">x_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">x_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">input_channels</span> <span class="o">=</span> <span class="n">x_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">x_flat</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">))</span>

    <span class="c1"># input kernel</span>
    <span class="n">Wi</span> <span class="o">=</span> <span class="n">kernel</span>
    <span class="n">Wi_x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_flat</span><span class="p">,</span> <span class="n">Wi</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
                       <span class="n">batch_shape</span> <span class="o">+</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">Wii_x</span><span class="p">,</span> <span class="n">Wif_x</span><span class="p">,</span> <span class="n">Wig_x</span><span class="p">,</span> <span class="n">Wio_x</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">Wi_x</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># recurrent kernel</span>
    <span class="n">Wh</span> <span class="o">=</span> <span class="n">recurrent_kernel</span>

    <span class="c1"># lstm states</span>
    <span class="n">ht</span> <span class="o">=</span> <span class="n">init_h</span>
    <span class="n">ct</span> <span class="o">=</span> <span class="n">init_c</span>

    <span class="c1"># lstm outputs</span>
    <span class="n">hts_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

    <span class="c1"># unrolled time dimension with lstm steps</span>
    <span class="k">for</span> <span class="n">Wii_xt</span><span class="p">,</span> <span class="n">Wif_xt</span><span class="p">,</span> <span class="n">Wig_xt</span><span class="p">,</span> <span class="n">Wio_xt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Wii_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span> <span class="n">ivy</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Wif_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span>
                                              <span class="n">ivy</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Wig_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span> <span class="n">ivy</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Wio_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)):</span>
        <span class="n">htm1</span> <span class="o">=</span> <span class="n">ht</span>
        <span class="n">ctm1</span> <span class="o">=</span> <span class="n">ct</span>

        <span class="n">Wh_htm1</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">htm1</span><span class="p">,</span> <span class="n">Wh</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">recurrent_bias</span> <span class="k">if</span> <span class="n">recurrent_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">Whi_htm1</span><span class="p">,</span> <span class="n">Whf_htm1</span><span class="p">,</span> <span class="n">Whg_htm1</span><span class="p">,</span> <span class="n">Who_htm1</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">Wh_htm1</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">it</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">Wii_xt</span> <span class="o">+</span> <span class="n">Whi_htm1</span><span class="p">)</span>
        <span class="n">ft</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">Wif_xt</span> <span class="o">+</span> <span class="n">Whf_htm1</span><span class="p">)</span>
        <span class="n">gt</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">Wig_xt</span> <span class="o">+</span> <span class="n">Whg_htm1</span><span class="p">)</span>
        <span class="n">ot</span> <span class="o">=</span> <span class="n">ivy</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">Wio_xt</span> <span class="o">+</span> <span class="n">Who_htm1</span><span class="p">)</span>
        <span class="n">ct</span> <span class="o">=</span> <span class="n">ft</span> <span class="o">*</span> <span class="n">ctm1</span> <span class="o">+</span> <span class="n">it</span> <span class="o">*</span> <span class="n">gt</span>
        <span class="n">ht</span> <span class="o">=</span> <span class="n">ot</span> <span class="o">*</span> <span class="n">ivy</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>

        <span class="n">hts_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ivy</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">ht</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">ivy</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">hts_list</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">ct</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ivy Team

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>